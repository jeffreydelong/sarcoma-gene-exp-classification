{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 20605)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# load the PCA model\n",
    "sarcoma_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-zscore-no-label-nomfs.csv')\n",
    "sarcoma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51154087  0.09480786 -0.35176093 ...  0.51624723  0.02346097\n",
      "   2.48359169]\n",
      " [-0.19129576  0.15347405  0.20261954 ... -0.41028013  2.86123234\n",
      "   0.16777757]\n",
      " [ 0.26472818  2.327348   -0.56049386 ... -0.21651268  0.0192731\n",
      "   0.76332633]\n",
      " ...\n",
      " [-0.2652622  -0.48026337 -1.16285933 ... -0.36779173  0.24949394\n",
      "  -0.36985907]\n",
      " [ 0.24931652 -0.03363532 -0.97441342 ... -0.50605902 -1.23871739\n",
      "   0.28153212]\n",
      " [-0.07085013 -0.29522455 -0.59015045 ... -0.50644652 -0.01137879\n",
      "  -0.39862195]]\n"
     ]
    }
   ],
   "source": [
    "# convert df to array\n",
    "sarcoma_data = sarcoma_df.to_numpy()\n",
    "print(sarcoma_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA fit is complete\n"
     ]
    }
   ],
   "source": [
    "# Run PCA based on preserving variance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(sarcoma_data)\n",
    "print(\"PCA fit is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA transformation is complete\n"
     ]
    }
   ],
   "source": [
    "X = pca.transform(sarcoma_data)\n",
    "print(\"PCA transformation is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced shape: (189, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"reduced shape: {}\".format(str(X.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in labels\n",
    "sarcoma_labels_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-labels-nomfs.csv')\n",
    "sarcoma_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 2 5 3 2 4 4 3 4 4 4 3 0 3 4 2 4 4 0 2 4 3 3 3 2 0 4 4 5 3 3 2 4 4 5 4\n",
      " 3 4 4 5 4 2 4 4 4 4 4 4 2 4 3 3 2 2 4 4 4 4 4 4 4 2 2 3 4 2 3 4 4 3 4 3 2\n",
      " 4 3 2 3 4 4 3 4 3 4 3 4 4 3 4 4 4 0 4 3 4 3 3 3 5 2 0 3 3 4 2 3 0 3 4 2 4\n",
      " 2 0 3 4 4 3 2 2 3 4 4 4 4 4 3 2 4 2 4 0 2 2 3 4 4 2 3 4 4 3 3 4 3 4 2 2 3\n",
      " 2 2 0 4 2 4 2 4 3 3 4 2 4 2 4 3 4 2 3 4 2 4 4 2 2 3 4 4 4 3 2 4 2 3 0 3 3\n",
      " 2 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Convert label df to np array\n",
    "y_df = sarcoma_labels_df['label']\n",
    "y = y_df.to_numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[ 0  2  3  4  5]\n",
      " [10 44 50 80  5]]\n"
     ]
    }
   ],
   "source": [
    "# Get a count of the unique values in each categories to make sure there are enough to support cross-validation\n",
    "unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "# Use Stratified Kfold split\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "k_fold = StratifiedKFold(n_splits=4,shuffle=True,random_state=2019)\n",
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2018, stratify=y)\n",
    "print(len(X_train))\n",
    "# Create k folds with training data\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7297297297297297\n",
      "1.0\n",
      "0.7428571428571429\n",
      "1.0\n",
      "0.6\n",
      "1.0\n",
      "0.8235294117647058\n",
      "0.7291666666666666\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the model\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    neigh.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = neigh.predict(X_train_fold)\n",
    "    y_test_pred = neigh.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(neigh.score(X_train_fold, y_train_pred))\n",
    "    # record generalization accuracy\n",
    "    print(neigh.score(X_cv_fold, y_cv_fold))\n",
    "print(neigh.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9711538461538461\n",
      "0.9459459459459459\n",
      "0.9622641509433962\n",
      "0.9714285714285714\n",
      "0.9716981132075472\n",
      "0.9428571428571428\n",
      "0.9532710280373832\n",
      "1.0\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    svc.fit(X_train, y_train) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = svc.predict(X_train_fold)\n",
    "    y_test_pred = svc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(svc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(svc.score(X_cv_fold, y_cv_fold))\n",
    "print(svc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9615384615384616\n",
      "0.4864864864864865\n",
      "0.9811320754716981\n",
      "0.6285714285714286\n",
      "1.0\n",
      "0.6\n",
      "0.9719626168224299\n",
      "0.5588235294117647\n",
      "0.6458333333333334\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=4, random_state=0, n_estimators=100) \n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    rfc.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = rfc.predict(X_train)\n",
    "    y_test_pred = rfc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(rfc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(rfc.score(X_cv_fold, y_cv_fold))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8108108108108109\n",
      "1.0\n",
      "0.9142857142857143\n",
      "1.0\n",
      "0.7714285714285715\n",
      "1.0\n",
      "0.8529411764705882\n",
      "0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrc = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    lrc.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = lrc.predict(X_train)\n",
    "    y_test_pred = lrc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(lrc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(lrc.score(X_cv_fold, y_cv_fold))\n",
    "print(lrc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number of Neighbors: 11\n",
      "Accuracy Score: 0.7708333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Specify number of neighbors as hyperparameter\n",
    "neighbors = range(1, 12)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_neighbors=neighbors)\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_knn = gs_knn.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best Number of Neighbors:', best_model_knn.best_estimator_.get_params()['n_neighbors'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_knn.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of C 100.0\n",
      "Best value of gamma 1e-07\n",
      "Accuracy Score: 0.8541666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create hyperparameter space\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C_range, gamma=gamma_range)\n",
    "gs_svm = GridSearchCV(SVC(kernel='rbf'), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_svm = gs_svm.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best value of C', best_model_svm.best_estimator_.get_params()['C'])\n",
    "print('Best value of gamma', best_model_svm.best_estimator_.get_params()['gamma'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of Max depth 7\n",
      "Accuracy Score: 0.6458333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create hyperparameter space\n",
    "maxdepth=range(1, 12)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(max_depth=maxdepth)\n",
    "gs_rfc = GridSearchCV(RandomForestClassifier(random_state=0, n_estimators=100), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_rfc = gs_rfc.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best value of Max depth', best_model_rfc.best_estimator_.get_params()['max_depth'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of C 1.0\n",
      "Accuracy Score: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Grid search for LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "gs_lrc = GridSearchCV(LogisticRegression(multi_class='multinomial', solver='sag', max_iter=5000, random_state=0, penalty='l2') , hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_lrc = gs_lrc.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best value of C', best_model_lrc.best_estimator_.get_params()['C'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_lrc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00         3\n",
      "     Class 1       0.80      0.73      0.76        11\n",
      "     Class 2       0.92      0.92      0.92        13\n",
      "     Class 3       0.90      0.90      0.90        20\n",
      "     Class 4       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.82      0.91      0.85        48\n",
      "weighted avg       0.88      0.88      0.88        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model is LR with C = 1\n",
    "lrc = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "lrc.fit(X_train, y_train) \n",
    "\n",
    "y_pred = lrc.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = [\"Class {}\".format(i) for i in range(5)]\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  0,  0,  0],\n",
       "       [ 0,  8,  1,  2,  0],\n",
       "       [ 0,  1, 12,  0,  0],\n",
       "       [ 0,  1,  0, 18,  1],\n",
       "       [ 0,  0,  0,  0,  1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting classifier\n",
    "def votingClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    log_clf = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "\n",
    "    svm_clf = SVC(kernel='rbf', gamma=1e-05, C=100)\n",
    "  \n",
    "    svm2_clf = SVC(kernel='rbf', gamma='scale', C=1)\n",
    "  \n",
    "    voting_clf = VotingClassifier(\n",
    "            estimators=[('lr', log_clf), ('svc', svm_clf), ('svc2', svm2_clf)],\n",
    "            voting='hard')\n",
    "     \n",
    "    for clf in (log_clf, svm_clf, svm2_clf, voting_clf):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.875\n",
      "SVC 0.8541666666666666\n",
      "SVC 0.875\n",
      "VotingClassifier 0.875\n"
     ]
    }
   ],
   "source": [
    "votingClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baggingClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(multi_class='multinomial', solver='sag', max_iter=2000, C=1.0, penalty='l2'), n_estimators=100,\n",
    "            max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "    bag_clf.fit(X_train, y_train)\n",
    "    y_pred = bag_clf.predict(X_test)\n",
    "    print('Bagging LR',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging LR 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "baggingClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(\n",
    "        LogisticRegression(multi_class='multinomial', solver='sag', max_iter=3000, C=1.0, penalty='l2'), n_estimators=100,\n",
    "             random_state=42)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    y_pred = ada_clf.predict(X_test)\n",
    "    print('AdaBoost LR', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost LR 0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "adaBoostClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
