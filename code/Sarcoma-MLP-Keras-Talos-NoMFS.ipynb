{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Talos and Keras\n",
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "import talos as ta\n",
    "from talos.utils import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.activations import relu, elu\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 20605)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the sarcoma transcriptome data\n",
    "sarcoma_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-zscore-no-label-nomfs.csv')\n",
    "sarcoma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load label data\n",
    "sarcoma_labels_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-labels-nomfs.csv')\n",
    "sarcoma_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51154087  0.09480786 -0.35176093 ...  0.51624723  0.02346097\n",
      "   2.48359169]\n",
      " [-0.19129576  0.15347405  0.20261954 ... -0.41028013  2.86123234\n",
      "   0.16777757]\n",
      " [ 0.26472818  2.327348   -0.56049386 ... -0.21651268  0.0192731\n",
      "   0.76332633]\n",
      " ...\n",
      " [-0.2652622  -0.48026337 -1.16285933 ... -0.36779173  0.24949394\n",
      "  -0.36985907]\n",
      " [ 0.24931652 -0.03363532 -0.97441342 ... -0.50605902 -1.23871739\n",
      "   0.28153212]\n",
      " [-0.07085013 -0.29522455 -0.59015045 ... -0.50644652 -0.01137879\n",
      "  -0.39862195]]\n"
     ]
    }
   ],
   "source": [
    "# Convert transcriptome df to np array\n",
    "X = sarcoma_df.to_numpy()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 2 5 3 2 4 4 3 4 4 4 3 0 3 4 2 4 4 0 2 4 3 3 3 2 0 4 4 5 3 3 2 4 4 5 4\n",
      " 3 4 4 5 4 2 4 4 4 4 4 4 2 4 3 3 2 2 4 4 4 4 4 4 4 2 2 3 4 2 3 4 4 3 4 3 2\n",
      " 4 3 2 3 4 4 3 4 3 4 3 4 4 3 4 4 4 0 4 3 4 3 3 3 5 2 0 3 3 4 2 3 0 3 4 2 4\n",
      " 2 0 3 4 4 3 2 2 3 4 4 4 4 4 3 2 4 2 4 0 2 2 3 4 4 2 3 4 4 3 3 4 3 4 2 2 3\n",
      " 2 2 0 4 2 4 2 4 3 3 4 2 4 2 4 3 4 2 3 4 2 4 4 2 2 3 4 4 4 3 2 4 2 3 0 3 3\n",
      " 2 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Convert label df to np array\n",
    "y_df = sarcoma_labels_df['label']\n",
    "y = y_df.to_numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_cat = to_categorical(y)\n",
    "print(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# remove 2n d column of zeros\n",
    "y_cat = np.delete(y_cat, np.s_[1:2], axis=1)   \n",
    "print(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2,\n",
    "    stratify=y_cat, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyper-parameters\n",
    "p = {\n",
    "    'learning_rate': [0.01, 0.005],\n",
    "    'l1_reg': [0, 0.0001],\n",
    "    'l2_reg': [0, 0.0001, 0.001],\n",
    "    'dropout': [0, 0.2, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add input parameters to the function\n",
    "def sarcoma(x_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(5000, activation='relu', input_dim=20605))\n",
    "    model.add(Dense(5000, kernel_regularizer=regularizers.l1_l2(params['l1_reg'],params['l2_reg']), activation='relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(5000, kernel_regularizer=regularizers.l1_l2(params['l1_reg'],params['l2_reg']), activation='relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    sgd = optimizers.SGD(lr=params['learning_rate'])\n",
    "#   sgd = optimizers.SGD(lr=0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(x=x_train, \n",
    "                    y=y_train,\n",
    "                    validation_data=[x_val, y_val],\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "    \n",
    "    # modify the output model\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 11.3252 - acc: 0.5083 - val_loss: 10.9351 - val_acc: 0.7097\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 10.4714 - acc: 0.8750 - val_loss: 10.8002 - val_acc: 0.7097\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.2447 - acc: 0.9667 - val_loss: 10.7447 - val_acc: 0.8065\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1885 - acc: 0.9750 - val_loss: 10.7141 - val_acc: 0.7742\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1230 - acc: 0.9917 - val_loss: 10.6871 - val_acc: 0.8065\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0881 - acc: 1.0000 - val_loss: 10.6694 - val_acc: 0.8065\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0706 - acc: 1.0000 - val_loss: 10.6612 - val_acc: 0.8710\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0616 - acc: 1.0000 - val_loss: 10.6534 - val_acc: 0.8710\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0441 - acc: 1.0000 - val_loss: 10.6474 - val_acc: 0.8710\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0410 - acc: 1.0000 - val_loss: 10.6416 - val_acc: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:59, 19.93s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 11.8128 - acc: 0.4500 - val_loss: 11.7041 - val_acc: 0.3871\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.7759 - acc: 0.7000 - val_loss: 10.9132 - val_acc: 0.6129\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.4760 - acc: 0.8500 - val_loss: 10.8032 - val_acc: 0.7097\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.2480 - acc: 0.9417 - val_loss: 10.7383 - val_acc: 0.6774\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1896 - acc: 0.9667 - val_loss: 10.7325 - val_acc: 0.7419\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1736 - acc: 0.9583 - val_loss: 10.6938 - val_acc: 0.8065\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1274 - acc: 0.9833 - val_loss: 10.6665 - val_acc: 0.7742\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1220 - acc: 0.9750 - val_loss: 10.6635 - val_acc: 0.7742\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0622 - acc: 0.9917 - val_loss: 10.6680 - val_acc: 0.8065\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0786 - acc: 0.9917 - val_loss: 10.6498 - val_acc: 0.7742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:39<02:38, 19.77s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 73.7166 - acc: 0.3750 - val_loss: 71.9722 - val_acc: 0.7097\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 71.8895 - acc: 0.7667 - val_loss: 71.8871 - val_acc: 0.8387\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 71.4024 - acc: 0.9250 - val_loss: 71.8513 - val_acc: 0.7097\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.2734 - acc: 0.9667 - val_loss: 71.6949 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.1658 - acc: 0.9917 - val_loss: 71.6900 - val_acc: 0.8065\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.1096 - acc: 1.0000 - val_loss: 71.6216 - val_acc: 0.7742\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.0618 - acc: 1.0000 - val_loss: 71.6116 - val_acc: 0.8065\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.0309 - acc: 1.0000 - val_loss: 71.5648 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 70.9915 - acc: 1.0000 - val_loss: 71.5654 - val_acc: 0.8065\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 70.9621 - acc: 1.0000 - val_loss: 71.5089 - val_acc: 0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:16<02:54, 24.91s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 72.9369 - acc: 0.3833 - val_loss: 72.3491 - val_acc: 0.5484\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 71.9908 - acc: 0.6917 - val_loss: 72.0381 - val_acc: 0.8065\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 71.5743 - acc: 0.9083 - val_loss: 72.1314 - val_acc: 0.6129\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.5209 - acc: 0.9083 - val_loss: 71.9025 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.4065 - acc: 0.9583 - val_loss: 71.8160 - val_acc: 0.8387\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.3455 - acc: 0.9583 - val_loss: 71.8236 - val_acc: 0.7742\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.2422 - acc: 1.0000 - val_loss: 71.7917 - val_acc: 0.8387\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.2714 - acc: 0.9667 - val_loss: 71.7742 - val_acc: 0.8387\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.1918 - acc: 0.9833 - val_loss: 71.7248 - val_acc: 0.8065\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 71.1729 - acc: 0.9917 - val_loss: 71.7030 - val_acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:53<02:52, 28.67s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.2689 - acc: 0.5417 - val_loss: 0.9308 - val_acc: 0.5161\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5045 - acc: 0.8250 - val_loss: 0.7502 - val_acc: 0.7097\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2230 - acc: 0.9833 - val_loss: 0.6952 - val_acc: 0.7097\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1412 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1183 - acc: 1.0000 - val_loss: 0.6256 - val_acc: 0.8387\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0929 - acc: 1.0000 - val_loss: 0.6120 - val_acc: 0.8065\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0726 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 0.8065\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0615 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 0.5842 - val_acc: 0.8065\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.5820 - val_acc: 0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [02:04<01:56, 23.21s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 1.9997 - acc: 0.3500 - val_loss: 0.9706 - val_acc: 0.6129\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2678 - acc: 0.9167 - val_loss: 0.7035 - val_acc: 0.7742\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0884 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.8387\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0548 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.8387\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.8387\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.8387\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6107 - val_acc: 0.8387\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.8387\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6065 - val_acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:13<01:16, 19.15s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 11.5162 - acc: 0.4583 - val_loss: 11.2207 - val_acc: 0.5806\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 10.4248 - acc: 0.8667 - val_loss: 10.6980 - val_acc: 0.7097\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.1165 - acc: 0.9750 - val_loss: 10.7852 - val_acc: 0.7097\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0585 - acc: 0.9917 - val_loss: 10.6699 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0302 - acc: 1.0000 - val_loss: 10.6371 - val_acc: 0.8065\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0186 - acc: 1.0000 - val_loss: 10.6172 - val_acc: 0.8065\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0187 - acc: 1.0000 - val_loss: 10.6083 - val_acc: 0.8065\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0079 - acc: 1.0000 - val_loss: 10.5988 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0060 - acc: 1.0000 - val_loss: 10.5982 - val_acc: 0.8387\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 10.0002 - acc: 1.0000 - val_loss: 10.5982 - val_acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:34<00:58, 19.55s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1.9963 - acc: 0.3500 - val_loss: 1.2351 - val_acc: 0.4839\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8277 - acc: 0.6917 - val_loss: 0.7717 - val_acc: 0.7419\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4647 - acc: 0.8167 - val_loss: 0.8275 - val_acc: 0.6452\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.2791 - acc: 0.9417 - val_loss: 0.6439 - val_acc: 0.8065\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1661 - acc: 0.9750 - val_loss: 0.6485 - val_acc: 0.8387\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1572 - acc: 0.9583 - val_loss: 0.5866 - val_acc: 0.8387\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1450 - acc: 0.9667 - val_loss: 0.5672 - val_acc: 0.8387\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.1520 - acc: 0.9583 - val_loss: 0.6126 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0989 - acc: 0.9833 - val_loss: 0.5987 - val_acc: 0.8387\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.0747 - acc: 0.9917 - val_loss: 0.6271 - val_acc: 0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:44<00:33, 16.63s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 63.4592 - acc: 0.4083 - val_loss: 62.5425 - val_acc: 0.6129\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 61.6099 - acc: 0.8333 - val_loss: 61.8061 - val_acc: 0.7419\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.3018 - acc: 0.9833 - val_loss: 61.7478 - val_acc: 0.8387\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.2273 - acc: 1.0000 - val_loss: 61.7123 - val_acc: 0.8387\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.1908 - acc: 1.0000 - val_loss: 61.6878 - val_acc: 0.8387\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.1673 - acc: 1.0000 - val_loss: 61.6601 - val_acc: 0.8710\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.1372 - acc: 1.0000 - val_loss: 61.6370 - val_acc: 0.8710\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.1158 - acc: 1.0000 - val_loss: 61.6208 - val_acc: 0.8387\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.0911 - acc: 1.0000 - val_loss: 61.5965 - val_acc: 0.8387\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 61.0718 - acc: 1.0000 - val_loss: 61.5747 - val_acc: 0.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:12<00:20, 20.08s/it]INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 4s 31ms/step - loss: 3.0266 - acc: 0.3333 - val_loss: 2.0709 - val_acc: 0.5484\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 1.7513 - acc: 0.7333 - val_loss: 1.7948 - val_acc: 0.6452\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.4920 - acc: 0.8167 - val_loss: 1.6820 - val_acc: 0.8710\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.3153 - acc: 0.9000 - val_loss: 1.6285 - val_acc: 0.8710\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.2104 - acc: 0.9417 - val_loss: 1.6080 - val_acc: 0.8710\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.2376 - acc: 0.9250 - val_loss: 1.6268 - val_acc: 0.8065\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.1467 - acc: 0.9667 - val_loss: 1.6201 - val_acc: 0.8387\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.1048 - acc: 0.9917 - val_loss: 1.6013 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.1083 - acc: 0.9750 - val_loss: 1.6186 - val_acc: 0.8065\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 1.0496 - acc: 1.0000 - val_loss: 1.6260 - val_acc: 0.8065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:32<00:00, 21.27s/it]\n"
     ]
    }
   ],
   "source": [
    "t = ta.Scan(x=X_train, y=y_train, params=p, model=sarcoma, experiment_name='sarcoma-mlp', val_split=.2, fraction_limit=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    }
   ],
   "source": [
    "bestmodel = t.best_model(metric='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5000)              103030000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5000)              25005000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5000)              25005000  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 25005     \n",
      "=================================================================\n",
      "Total params: 153,065,005\n",
      "Trainable params: 153,065,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bestmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>dropout</th>\n",
       "      <th>l1_reg</th>\n",
       "      <th>l2_reg</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10.641623</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>10.041041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>71.702972</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>71.172902</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.606533</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>10.598196</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>10.000211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>61.574654</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>61.071756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>71.508896</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>70.962073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.581986</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.627085</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.074653</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.626045</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>1.049650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10.649786</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>10.078622</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs   val_loss   val_acc       loss       acc  dropout  l1_reg  \\\n",
       "0            10  10.641623  0.870968  10.041041  1.000000      0.2  0.0000   \n",
       "3            10  71.702972  0.838710  71.172902  0.991667      0.5  0.0001   \n",
       "5            10   0.606533  0.838710   0.016581  1.000000      0.2  0.0000   \n",
       "6            10  10.598196  0.838710  10.000211  1.000000      0.2  0.0000   \n",
       "8            10  61.574654  0.838710  61.071756  1.000000      0.2  0.0001   \n",
       "2            10  71.508896  0.806452  70.962073  1.000000      0.5  0.0001   \n",
       "4            10   0.581986  0.806452   0.043034  1.000000      0.2  0.0000   \n",
       "7            10   0.627085  0.806452   0.074653  0.991667      0.5  0.0000   \n",
       "9            10   1.626045  0.806452   1.049650  1.000000      0.5  0.0000   \n",
       "1            10  10.649786  0.774194  10.078622  0.991667      0.5  0.0000   \n",
       "\n",
       "   l2_reg  learning_rate  \n",
       "0  0.0010          0.005  \n",
       "3  0.0010          0.005  \n",
       "5  0.0000          0.010  \n",
       "6  0.0010          0.010  \n",
       "8  0.0000          0.010  \n",
       "2  0.0010          0.010  \n",
       "4  0.0000          0.005  \n",
       "7  0.0000          0.005  \n",
       "9  0.0001          0.005  \n",
       "1  0.0010          0.005  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data.sort_values('val_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = ta.Analyze(t)\n",
    "a.plot_corr('val_acc', ['loss', 'acc', 'precision', 'recall', 'f1score',\n",
    "                            'val_loss', 'val_acc', 'val_precision', 'val_recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 37ms/step\n",
      "test loss: 10.57\n",
      "test accuracy: 0.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "bestmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "print(\"\"\"test loss: %.2f\n",
    "test accuracy: %.2f\n",
    "\"\"\" % tuple(bestmodel.evaluate(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.25      0.50      0.33         2\n",
      "     Class 1       0.75      0.67      0.71         9\n",
      "     Class 2       0.82      0.90      0.86        10\n",
      "     Class 3       0.80      0.75      0.77        16\n",
      "     Class 4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.74        38\n",
      "   macro avg       0.52      0.56      0.53        38\n",
      "weighted avg       0.74      0.74      0.74        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = bestmodel.predict(X_test)\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(5)]\n",
    "y_test_classes = np.argmax(y_test, axis=-1)\n",
    "print(classification_report(y_test_classes, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0,  1,  0],\n",
       "       [ 2,  6,  0,  1,  0],\n",
       "       [ 0,  0,  9,  1,  0],\n",
       "       [ 1,  2,  1, 12,  0],\n",
       "       [ 0,  0,  1,  0,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
