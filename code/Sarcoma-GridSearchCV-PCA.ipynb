{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 163)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# load the PCA model\n",
    "sarcoma_pca_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-zscore-no-label-pca.csv')\n",
    "sarcoma_pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.1299698   19.54480635 -46.93123398 ...  -5.20201632  -6.68736361\n",
      "    2.18412099]\n",
      " [ 21.38528472 -34.44671658 -29.18157729 ... -10.89246806   1.2741249\n",
      "    7.78042611]\n",
      " [ 57.2761131    7.93957393   9.81154604 ...   3.43791233 -11.25802252\n",
      "   -5.61020023]\n",
      " ...\n",
      " [ 78.94052539  27.36499822  12.99505297 ...   1.6504554   -0.35151221\n",
      "    6.23520363]\n",
      " [  8.56846777 -21.26322469   9.74749633 ...  10.69648535   0.19657854\n",
      "    3.12135705]\n",
      " [ 19.09385664 -14.72218889 -10.0079258  ...   4.28801274  -1.52572152\n",
      "   -6.56352494]]\n"
     ]
    }
   ],
   "source": [
    "# convert df to array\n",
    "X = sarcoma_pca_df.to_numpy()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in labels\n",
    "sarcoma_labels_df = pd.read_csv('../Data/sarcoma-gene-exp-FPKM-labels-only.csv')\n",
    "sarcoma_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 2 1 5 3 2 4 4 3 4 4 4 3 0 3 1 4 2 4 4 0 2 4 3 3 3 2 0 4 4 5 3 3 2 4 4\n",
      " 5 4 3 4 4 5 4 2 4 4 4 1 4 1 4 4 2 4 3 3 2 2 4 4 4 4 4 4 4 2 2 3 4 2 3 4 4\n",
      " 3 4 3 2 4 3 2 3 4 4 3 4 3 4 3 4 4 1 3 4 4 4 0 4 3 4 3 3 3 5 2 0 3 3 1 1 4\n",
      " 2 3 0 3 4 2 4 2 0 3 4 4 3 2 2 1 3 4 4 4 4 4 3 2 4 2 4 1 0 2 2 3 4 4 2 3 4\n",
      " 4 3 1 3 4 3 4 2 2 1 3 2 2 0 4 2 1 4 2 1 4 3 3 4 2 4 2 4 3 4 2 1 3 4 2 4 4\n",
      " 2 2 3 4 4 4 3 2 4 1 1 2 3 0 3 3 2 2 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Convert label df to np array\n",
    "y_df = sarcoma_labels_df['label']\n",
    "y = y_df.to_numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[ 0  1  2  3  4  5]\n",
      " [10 17 44 50 80  5]]\n"
     ]
    }
   ],
   "source": [
    "# Get a count of the unique values in each categories to make sure there are enough to support cross-validation\n",
    "unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "# Use Stratified Kfold split\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "k_fold = StratifiedKFold(n_splits=4,shuffle=True,random_state=2019)\n",
    "# Split training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2018, stratify=y)\n",
    "print(len(X_train))\n",
    "# Create k folds with training data\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6341463414634146\n",
      "1.0\n",
      "0.6578947368421053\n",
      "1.0\n",
      "0.7894736842105263\n",
      "1.0\n",
      "0.7837837837837838\n",
      "0.6346153846153846\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the model\n",
    "neigh = KNeighborsClassifier(n_neighbors=7)\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    neigh.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = neigh.predict(X_train_fold)\n",
    "    y_test_pred = neigh.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(neigh.score(X_train_fold, y_train_pred))\n",
    "    # record generalization accuracy\n",
    "    print(neigh.score(X_cv_fold, y_cv_fold))\n",
    "print(neigh.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9469026548672567\n",
      "0.9024390243902439\n",
      "0.9396551724137931\n",
      "0.9210526315789473\n",
      "0.9137931034482759\n",
      "1.0\n",
      "0.9401709401709402\n",
      "0.918918918918919\n",
      "0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    svc.fit(X_train, y_train) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = svc.predict(X_train_fold)\n",
    "    y_test_pred = svc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(svc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(svc.score(X_cv_fold, y_cv_fold))\n",
    "print(svc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911504424778761\n",
      "0.4878048780487805\n",
      "0.9741379310344828\n",
      "0.6052631578947368\n",
      "0.9568965517241379\n",
      "0.5526315789473685\n",
      "0.9572649572649573\n",
      "0.5675675675675675\n",
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=4, random_state=0, n_estimators=100) \n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    rfc.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = rfc.predict(X_train)\n",
    "    y_test_pred = rfc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(rfc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(rfc.score(X_cv_fold, y_cv_fold))\n",
    "print(rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7317073170731707\n",
      "1.0\n",
      "0.631578947368421\n",
      "1.0\n",
      "0.868421052631579\n",
      "1.0\n",
      "0.8108108108108109\n",
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrc = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
    "    X_train_fold, X_cv_fold = X_train[train_index,:], X_train[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train[train_index], y_train[cv_index]\n",
    "    lrc.fit(X_train_fold, y_train_fold) \n",
    "    # model evaluation for training set\n",
    "    y_train_pred = lrc.predict(X_train)\n",
    "    y_test_pred = lrc.predict(X_cv_fold)\n",
    "    # record training set accuracy\n",
    "    print(lrc.score(X_train_fold, y_train_fold))\n",
    "    # record generalization accuracy\n",
    "    print(lrc.score(X_cv_fold, y_cv_fold))\n",
    "print(lrc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number of Neighbors: 5\n",
      "Accuracy Score: 0.5961538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Specify number of neighbors as hyperparameter\n",
    "neighbors = range(1, 12)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_neighbors=neighbors)\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_knn = gs_knn.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best Number of Neighbors:', best_model_knn.best_estimator_.get_params()['n_neighbors'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_knn.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of C 100.0\n",
      "Best value of gamma 1e-05\n",
      "Accuracy Score: 0.7884615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create hyperparameter space\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C_range, gamma=gamma_range)\n",
    "gs_svm = GridSearchCV(SVC(kernel='rbf'), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_svm = gs_svm.fit(X_train, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best value of C', best_model_svm.best_estimator_.get_params()['C'])\n",
    "print('Best value of gamma', best_model_svm.best_estimator_.get_params()['gamma'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of Max depth 5\n",
      "Accuracy Score: 0.5961538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create hyperparameter space\n",
    "maxdepth=range(1, 12)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(max_depth=maxdepth)\n",
    "gs_rfc = GridSearchCV(RandomForestClassifier(random_state=0, n_estimators=100), hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_rfc = gs_rfc.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best value of Max depth', best_model_rfc.best_estimator_.get_params()['max_depth'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreydelong/plaidml-venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of C 1.0\n",
      "Accuracy Score: 0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "# Grid search for LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "gs_lrc = GridSearchCV(LogisticRegression(multi_class='multinomial', solver='sag', max_iter=5000, random_state=0, penalty='l2') , hyperparameters, cv=4, scoring=\"accuracy\", verbose=0)\n",
    "# Fit search\n",
    "best_model_lrc = gs_lrc.fit(X_train, y_train)\n",
    "    \n",
    "# View best hyperparameters\n",
    "print('Best value of C', best_model_lrc.best_estimator_.get_params()['C'])\n",
    "\n",
    "# Test the model and report Accuracy score\n",
    "print('Accuracy Score:', accuracy_score(y_test, best_model_lrc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00         3\n",
      "     Class 1       0.50      0.25      0.33         4\n",
      "     Class 2       0.60      0.82      0.69        11\n",
      "     Class 3       0.92      0.92      0.92        13\n",
      "     Class 4       0.94      0.85      0.89        20\n",
      "     Class 5       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.83        52\n",
      "   macro avg       0.83      0.81      0.81        52\n",
      "weighted avg       0.84      0.83      0.82        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model is LR with C = 1\n",
    "lrc = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "lrc.fit(X_train, y_train) \n",
    "\n",
    "y_pred = lrc.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = [\"Class {}\".format(i) for i in range(6)]\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  3,  0,  0,  0],\n",
       "       [ 0,  0,  9,  1,  1,  0],\n",
       "       [ 0,  1,  0, 12,  0,  0],\n",
       "       [ 0,  0,  3,  0, 17,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting classifier\n",
    "def votingClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    log_clf = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=1000, C=1.0, random_state=0, penalty='l2') \n",
    "\n",
    "    svm_clf = SVC(kernel='rbf', gamma=1e-05, C=100)\n",
    "  \n",
    "    svm2_clf = SVC(kernel='rbf', gamma='scale', C=1)\n",
    "  \n",
    "    voting_clf = VotingClassifier(\n",
    "            estimators=[('lr', log_clf), ('svc', svm_clf), ('svc2', svm2_clf)],\n",
    "            voting='hard')\n",
    "     \n",
    "    for clf in (log_clf, svm_clf, svm2_clf, voting_clf):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8269230769230769\n",
      "SVC 0.7884615384615384\n",
      "SVC 0.7115384615384616\n",
      "VotingClassifier 0.7884615384615384\n"
     ]
    }
   ],
   "source": [
    "votingClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baggingClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    bag_clf = BaggingClassifier(\n",
    "        LogisticRegression(multi_class='multinomial', solver='sag', max_iter=2000, C=1.0, penalty='l2'), n_estimators=100,\n",
    "            max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "    bag_clf.fit(X_train, y_train)\n",
    "    y_pred = bag_clf.predict(X_test)\n",
    "    print('Bagging LR',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging LR 0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "baggingClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostClassifiers():\n",
    "    # This example is taken from https://github.com/ageron/handson-ml/blob/master/07_ensemble_learning_and_random_forests.ipynb \n",
    "\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(\n",
    "        LogisticRegression(multi_class='multinomial', solver='sag', max_iter=3000, C=1.0, penalty='l2'), n_estimators=100,\n",
    "             random_state=42)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    y_pred = ada_clf.predict(X_test)\n",
    "    print('AdaBoost LR', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost LR 0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "adaBoostClassifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
